{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "64a42a09",
      "metadata": {
        "id": "64a42a09"
      },
      "source": [
        "# Video Classifier to predict Drunkenness level\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "59b4b70e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59b4b70e",
        "outputId": "5241be13-ef1e-4218-b34e-9625e1fb3d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dangerously_drunk', 'sober', 'moderatly_drunk', 'lightly_drunk', '.ipynb_checkpoints']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "dataset_path = os.listdir('/content/drive/MyDrive/Colab Notebooks/dataset/train')\n",
        "\n",
        "label_types = os.listdir('/content/drive/MyDrive/Colab Notebooks/dataset/train')\n",
        "print (label_types)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8e5998ZuTZd",
        "outputId": "a13b06d9-d11a-478b-c027-8bfff2d6c973"
      },
      "id": "_8e5998ZuTZd",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935f06c4",
      "metadata": {
        "id": "935f06c4"
      },
      "source": [
        "# Preparing Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d7e00542",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7e00542",
        "outputId": "19ca8d4a-2e57-4b22-d4bb-3fd9d49568c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 tag                                         video_name\n",
            "0  dangerously_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "1  dangerously_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "2  dangerously_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "3  dangerously_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "4  dangerously_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "              tag                                         video_name\n",
            "23  lightly_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "24  lightly_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "25  lightly_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "26  lightly_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "27  lightly_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n"
          ]
        }
      ],
      "source": [
        "rooms = []\n",
        "\n",
        "for item in dataset_path:\n",
        " # Get all the file names\n",
        " all_rooms = os.listdir('/content/drive/MyDrive/Colab Notebooks/dataset/train' + '/' +item)\n",
        "\n",
        " # Add them to the list\n",
        " for room in all_rooms:\n",
        "    rooms.append((item, str('/content/drive/MyDrive/Colab Notebooks/dataset/train' + '/' +item) + '/' + room))\n",
        "\n",
        "# Build a dataframe\n",
        "train_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])\n",
        "print(train_df.head())\n",
        "print(train_df.tail())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "27ac79ad",
      "metadata": {
        "id": "27ac79ad"
      },
      "outputs": [],
      "source": [
        "df = train_df.loc[:,['video_name','tag']]\n",
        "df\n",
        "df.to_csv('train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee0897c2",
      "metadata": {
        "id": "ee0897c2"
      },
      "source": [
        "# Preparing Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "413b31f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "413b31f2",
        "outputId": "2557af59-0847-47a3-8da5-7861f8c83b43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['moderatly_drunk', 'dangerously_drunk', 'lightly_drunk', 'sober']\n",
            "Types of activities found:  4\n",
            "                 tag                                         video_name\n",
            "0    moderatly_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "1    moderatly_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "2  dangerously_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "3  dangerously_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "4  dangerously_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "                 tag                                         video_name\n",
            "4  dangerously_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "5      lightly_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "6      lightly_drunk  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "7              sober  /content/drive/MyDrive/Colab Notebooks/dataset...\n",
            "8              sober  /content/drive/MyDrive/Colab Notebooks/dataset...\n"
          ]
        }
      ],
      "source": [
        "dataset_path = os.listdir('/content/drive/MyDrive/Colab Notebooks/dataset/test')\n",
        "print(dataset_path)\n",
        "\n",
        "room_types = os.listdir('/content/drive/MyDrive/Colab Notebooks/dataset/test')\n",
        "print(\"Types of activities found: \", len(dataset_path))\n",
        "\n",
        "rooms = []\n",
        "\n",
        "for item in dataset_path:\n",
        " # Get all the file names\n",
        " all_rooms = os.listdir('/content/drive/MyDrive/Colab Notebooks/dataset/test' + '/' +item)\n",
        "\n",
        " # Add them to the list\n",
        " for room in all_rooms:\n",
        "    rooms.append((item, str('/content/drive/MyDrive/Colab Notebooks/dataset/test' + '/' +item) + '/' + room))\n",
        "\n",
        "# Build a dataframe\n",
        "test_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])\n",
        "print(test_df.head())\n",
        "print(test_df.tail())\n",
        "\n",
        "df = test_df.loc[:,['video_name','tag']]\n",
        "df\n",
        "df.to_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f698e5d-5c11-411c-801d-9d4e54b95f8d",
      "metadata": {
        "id": "6f698e5d-5c11-411c-801d-9d4e54b95f8d",
        "outputId": "f08338a1-bafa-4f4d-ffe5-df750b6868d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (2.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: setuptools in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.48.2)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.29.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\vicma\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c45fb7c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c45fb7c1",
        "outputId": "eee0b3ec-4cdb-4551-ccbb-1ec9b9c0586e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-gkfwx0d9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-gkfwx0d9\n",
            "  Resolved https://github.com/tensorflow/docs to commit 344f0e9c1d12a7c8127ae5359f485c462e18854b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astor (from tensorflow-docs==2024.10.14.18741)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.10.14.18741) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.10.14.18741) (3.1.4)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.10.14.18741) (5.10.4)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.10.14.18741) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.10.14.18741) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow-docs==2024.10.14.18741) (3.0.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.10.14.18741) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.10.14.18741) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.10.14.18741) (5.7.2)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.10.14.18741) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.10.14.18741) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.10.14.18741) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.10.14.18741) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.10.14.18741) (0.20.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->tensorflow-docs==2024.10.14.18741) (4.3.6)\n",
            "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-2024.10.14.18741-py3-none-any.whl size=182607 sha256=c0a25f1eb42e12f41a3631a0b7767249a2647687053ea72b52debad1c80a0a1f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ws054j_n/wheels/86/0f/1e/3b62293c8ffd0fd5a49508e6871cdb7554abe9c62afd35ec53\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: astor, tensorflow-docs\n",
            "Successfully installed astor-0.8.1 tensorflow-docs-2024.10.14.18741\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "918d9338",
      "metadata": {
        "id": "918d9338"
      },
      "outputs": [],
      "source": [
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f4fed40c",
      "metadata": {
        "id": "f4fed40c"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
        "  except RuntimeError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bdf44bb",
      "metadata": {
        "id": "2bdf44bb"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8b716cfb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "8b716cfb",
        "outputId": "88c42c85-e03b-46fd-fadb-c07cd5bda93d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total videos for training: 28\n",
            "Total videos for testing: 9\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0                                   video_name                tag\n",
              "7            7   dataset/train/dangerously_drunk/video5.mp4  dangerously_drunk\n",
              "10          10   dataset/train/dangerously_drunk/video8.mp4  dangerously_drunk\n",
              "2            2  dataset/train/dangerously_drunk/video11.mp4  dangerously_drunk\n",
              "19          19     dataset/train/moderatly_drunk/video4.mp4    moderatly_drunk\n",
              "18          18     dataset/train/moderatly_drunk/video3.mp4    moderatly_drunk\n",
              "22          22     dataset/train/moderatly_drunk/video7.mp4    moderatly_drunk\n",
              "17          17     dataset/train/moderatly_drunk/video1.mp4    moderatly_drunk\n",
              "20          20     dataset/train/moderatly_drunk/video5.mp4    moderatly_drunk\n",
              "13          13       dataset/train/lightly_drunk/video2.mp4      lightly_drunk\n",
              "12          12       dataset/train/lightly_drunk/video1.mp4      lightly_drunk"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0885774f-e647-4c30-8356-c452b8c7a44c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>video_name</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>dataset/train/dangerously_drunk/video5.mp4</td>\n",
              "      <td>dangerously_drunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>dataset/train/dangerously_drunk/video8.mp4</td>\n",
              "      <td>dangerously_drunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>dataset/train/dangerously_drunk/video11.mp4</td>\n",
              "      <td>dangerously_drunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>dataset/train/moderatly_drunk/video4.mp4</td>\n",
              "      <td>moderatly_drunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>dataset/train/moderatly_drunk/video3.mp4</td>\n",
              "      <td>moderatly_drunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>dataset/train/moderatly_drunk/video7.mp4</td>\n",
              "      <td>moderatly_drunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>dataset/train/moderatly_drunk/video1.mp4</td>\n",
              "      <td>moderatly_drunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>dataset/train/moderatly_drunk/video5.mp4</td>\n",
              "      <td>moderatly_drunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>dataset/train/lightly_drunk/video2.mp4</td>\n",
              "      <td>lightly_drunk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>dataset/train/lightly_drunk/video1.mp4</td>\n",
              "      <td>lightly_drunk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0885774f-e647-4c30-8356-c452b8c7a44c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0885774f-e647-4c30-8356-c452b8c7a44c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0885774f-e647-4c30-8356-c452b8c7a44c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-df351e08-d5fc-4b26-8a58-181b16138c0d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df351e08-d5fc-4b26-8a58-181b16138c0d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-df351e08-d5fc-4b26-8a58-181b16138c0d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 2,\n        \"max\": 22,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          13,\n          10,\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"dataset/train/lightly_drunk/video2.mp4\",\n          \"dataset/train/dangerously_drunk/video8.mp4\",\n          \"dataset/train/moderatly_drunk/video7.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"dangerously_drunk\",\n          \"moderatly_drunk\",\n          \"lightly_drunk\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test.csv\")\n",
        "\n",
        "print(f\"Total videos for training: {len(train_df)}\")\n",
        "print(f\"Total videos for testing: {len(test_df)}\")\n",
        "\n",
        "\n",
        "train_df.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93c182a",
      "metadata": {
        "id": "b93c182a"
      },
      "source": [
        "# Feed the videos to a network:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fcd68b72",
      "metadata": {
        "id": "fcd68b72"
      },
      "outputs": [],
      "source": [
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c243c6ee",
      "metadata": {
        "id": "c243c6ee"
      },
      "source": [
        "   ### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "388c0afe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "388c0afe",
        "outputId": "06948ff4-9241-4ed4-bad5-17c04912fa66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.InceptionV3(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    )\n",
        "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "\n",
        "\n",
        "feature_extractor = build_feature_extractor()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "877ca626",
      "metadata": {
        "id": "877ca626"
      },
      "source": [
        "### Label Encoding\n",
        "StringLookup layer encode the class labels as integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "801339d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "801339d8",
        "outputId": "82d564d0-3d84-4545-cbd7-d7849d71a1a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dangerously_drunk', 'lightly_drunk', 'moderatly_drunk', 'sober']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]))\n",
        "print(label_processor.get_vocabulary())\n",
        "\n",
        "labels = train_df[\"tag\"].values\n",
        "labels = label_processor(labels[..., None]).numpy()\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fde4ac85",
      "metadata": {
        "id": "fde4ac85"
      },
      "source": [
        "Finally, we can put all the pieces together to create our data processing utility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18db18a3",
      "metadata": {
        "id": "18db18a3"
      },
      "outputs": [],
      "source": [
        "#print(train_data[0].shape)\n",
        "#train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "76216366",
      "metadata": {
        "id": "76216366"
      },
      "outputs": [],
      "source": [
        "#Define hyperparameters\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "\n",
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "11befa62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11befa62",
        "outputId": "7d2dd330-fe67-4a50-de11-0042c6c80edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame features in train set: (28, 20, 2048)\n",
            "Frame masks in train set: (28, 20)\n",
            "train_labels in train set: (28, 1)\n",
            "test_labels in train set: (9, 1)\n"
          ]
        }
      ],
      "source": [
        "def prepare_all_videos(df, root_dir):\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"video_name\"].values.tolist()\n",
        "\n",
        "    ##take all classlabels from train_df column named 'tag' and store in labels\n",
        "    labels = df[\"tag\"].values\n",
        "\n",
        "    #convert classlabels to label encoding\n",
        "    labels = label_processor(labels[..., None]).numpy()\n",
        "\n",
        "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
        "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
        "    # masked with padding or not.\n",
        "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\") # 145,20\n",
        "    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\") #145,20,2048\n",
        "\n",
        "    # For each video.\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        # Gather all its frames and add a batch dimension.\n",
        "        frames = load_video(os.path.join(root_dir, path))\n",
        "        frames = frames[None, ...]\n",
        "\n",
        "        # Initialize placeholders to store the masks and features of the current video.\n",
        "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "        temp_frame_features = np.zeros(\n",
        "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "        )\n",
        "\n",
        "        # Extract features from the frames of the current video.\n",
        "        for i, batch in enumerate(frames):\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            for j in range(length):\n",
        "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
        "                    batch[None, j, :]\n",
        "                )\n",
        "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
        "\n",
        "    return (frame_features, frame_masks), labels\n",
        "\n",
        "\n",
        "train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
        "test_data, test_labels = prepare_all_videos(test_df, \"test\")\n",
        "\n",
        "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
        "print(f\"Frame masks in train set: {train_data[1].shape}\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"train_labels in train set: {train_labels.shape}\")\n",
        "\n",
        "print(f\"test_labels in train set: {test_labels.shape}\")\n",
        "\n",
        "# MAX_SEQ_LENGTH = 20, NUM_FEATURES = 2048. We have defined this above under hyper parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "407e0827",
      "metadata": {
        "id": "407e0827"
      },
      "source": [
        "# The sequence model\n",
        "Now, we can feed this data to a sequence model consisting of recurrent layers like GRU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7382f3c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7382f3c1",
        "outputId": "983510fe-8939-402b-b4b8-95633e76bcde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6316 - loss: 1.3863\n",
            "Epoch 1: val_loss improved from inf to 1.38729, saving model to ./content/drive/MyDrive/Colab Notebooks/tmp/checkpoint.weights.h5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 0.6316 - loss: 1.3863 - val_accuracy: 0.0000e+00 - val_loss: 1.3873\n",
            "Epoch 2/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6316 - loss: 1.3855\n",
            "Epoch 2: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6316 - loss: 1.3855 - val_accuracy: 0.0000e+00 - val_loss: 1.3883\n",
            "Epoch 3/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6316 - loss: 1.3847\n",
            "Epoch 3: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.6316 - loss: 1.3847 - val_accuracy: 0.0000e+00 - val_loss: 1.3893\n",
            "Epoch 4/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6316 - loss: 1.3839\n",
            "Epoch 4: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.6316 - loss: 1.3839 - val_accuracy: 0.0000e+00 - val_loss: 1.3903\n",
            "Epoch 5/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6316 - loss: 1.3831\n",
            "Epoch 5: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.6316 - loss: 1.3831 - val_accuracy: 0.0000e+00 - val_loss: 1.3913\n",
            "Epoch 6/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6316 - loss: 1.3824\n",
            "Epoch 6: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.6316 - loss: 1.3824 - val_accuracy: 0.0000e+00 - val_loss: 1.3923\n",
            "Epoch 7/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6316 - loss: 1.3816\n",
            "Epoch 7: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.6316 - loss: 1.3816 - val_accuracy: 0.0000e+00 - val_loss: 1.3933\n",
            "Epoch 8/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6316 - loss: 1.3808\n",
            "Epoch 8: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6316 - loss: 1.3808 - val_accuracy: 0.0000e+00 - val_loss: 1.3943\n",
            "Epoch 9/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.6316 - loss: 1.3800\n",
            "Epoch 9: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.6316 - loss: 1.3800 - val_accuracy: 0.0000e+00 - val_loss: 1.3953\n",
            "Epoch 10/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6316 - loss: 1.3792\n",
            "Epoch 10: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.6316 - loss: 1.3792 - val_accuracy: 0.0000e+00 - val_loss: 1.3963\n",
            "Epoch 11/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6316 - loss: 1.3785\n",
            "Epoch 11: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6316 - loss: 1.3785 - val_accuracy: 0.0000e+00 - val_loss: 1.3973\n",
            "Epoch 12/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6316 - loss: 1.3777\n",
            "Epoch 12: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6316 - loss: 1.3777 - val_accuracy: 0.0000e+00 - val_loss: 1.3983\n",
            "Epoch 13/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6316 - loss: 1.3769\n",
            "Epoch 13: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6316 - loss: 1.3769 - val_accuracy: 0.0000e+00 - val_loss: 1.3993\n",
            "Epoch 14/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6316 - loss: 1.3761\n",
            "Epoch 14: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.6316 - loss: 1.3761 - val_accuracy: 0.0000e+00 - val_loss: 1.4003\n",
            "Epoch 15/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6316 - loss: 1.3753\n",
            "Epoch 15: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.6316 - loss: 1.3753 - val_accuracy: 0.0000e+00 - val_loss: 1.4013\n",
            "Epoch 16/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.6316 - loss: 1.3746\n",
            "Epoch 16: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.6316 - loss: 1.3746 - val_accuracy: 0.0000e+00 - val_loss: 1.4023\n",
            "Epoch 17/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.6316 - loss: 1.3738\n",
            "Epoch 17: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.6316 - loss: 1.3738 - val_accuracy: 0.0000e+00 - val_loss: 1.4033\n",
            "Epoch 18/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6316 - loss: 1.3730\n",
            "Epoch 18: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.6316 - loss: 1.3730 - val_accuracy: 0.0000e+00 - val_loss: 1.4043\n",
            "Epoch 19/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6316 - loss: 1.3723\n",
            "Epoch 19: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.6316 - loss: 1.3723 - val_accuracy: 0.0000e+00 - val_loss: 1.4053\n",
            "Epoch 20/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6316 - loss: 1.3715\n",
            "Epoch 20: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.6316 - loss: 1.3715 - val_accuracy: 0.0000e+00 - val_loss: 1.4063\n",
            "Epoch 21/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6316 - loss: 1.3707\n",
            "Epoch 21: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.6316 - loss: 1.3707 - val_accuracy: 0.0000e+00 - val_loss: 1.4073\n",
            "Epoch 22/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6316 - loss: 1.3700\n",
            "Epoch 22: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.6316 - loss: 1.3700 - val_accuracy: 0.0000e+00 - val_loss: 1.4083\n",
            "Epoch 23/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6316 - loss: 1.3692\n",
            "Epoch 23: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6316 - loss: 1.3692 - val_accuracy: 0.0000e+00 - val_loss: 1.4093\n",
            "Epoch 24/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6316 - loss: 1.3684\n",
            "Epoch 24: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6316 - loss: 1.3684 - val_accuracy: 0.0000e+00 - val_loss: 1.4103\n",
            "Epoch 25/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6316 - loss: 1.3677\n",
            "Epoch 25: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6316 - loss: 1.3677 - val_accuracy: 0.0000e+00 - val_loss: 1.4113\n",
            "Epoch 26/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6316 - loss: 1.3669\n",
            "Epoch 26: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.6316 - loss: 1.3669 - val_accuracy: 0.0000e+00 - val_loss: 1.4123\n",
            "Epoch 27/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6316 - loss: 1.3662\n",
            "Epoch 27: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6316 - loss: 1.3662 - val_accuracy: 0.0000e+00 - val_loss: 1.4133\n",
            "Epoch 28/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6316 - loss: 1.3654\n",
            "Epoch 28: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.6316 - loss: 1.3654 - val_accuracy: 0.0000e+00 - val_loss: 1.4142\n",
            "Epoch 29/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6316 - loss: 1.3646\n",
            "Epoch 29: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6316 - loss: 1.3646 - val_accuracy: 0.0000e+00 - val_loss: 1.4152\n",
            "Epoch 30/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.6316 - loss: 1.3639\n",
            "Epoch 30: val_loss did not improve from 1.38729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.6316 - loss: 1.3639 - val_accuracy: 0.0000e+00 - val_loss: 1.4162\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3333 - loss: 1.3862\n",
            "Test accuracy: 33.33%\n"
          ]
        }
      ],
      "source": [
        "# Utility for our sequence model.\n",
        "def get_sequence_model():\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "\n",
        "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
        "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
        "    x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n",
        "    x = keras.layers.GRU(8)(x)\n",
        "    x = keras.layers.Dropout(0.4)(x)\n",
        "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
        "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
        "\n",
        "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
        "\n",
        "    rnn_model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return rnn_model\n",
        "\n",
        "EPOCHS = 30\n",
        "# Utility for running experiments.\n",
        "def run_experiment():\n",
        "    filepath = \"./content/drive/MyDrive/Colab Notebooks/tmp/checkpoint.weights.h5\"\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
        "    )\n",
        "\n",
        "    seq_model = get_sequence_model()\n",
        "    history = seq_model.fit(\n",
        "        [train_data[0], train_data[1]],\n",
        "        train_labels,\n",
        "        validation_split=0.3,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[checkpoint],\n",
        "    )\n",
        "\n",
        "    seq_model.load_weights(filepath)\n",
        "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history, seq_model\n",
        "\n",
        "\n",
        "_, sequence_model = run_experiment()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f1f1681",
      "metadata": {
        "id": "6f1f1681"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "846a5956",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "846a5956",
        "outputId": "6c661d80-a94a-497f-a65e-8258a5dce080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test video path: dataset/test/dangerously_drunk/video1.mp4\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step\n",
            "  dangerously_drunk: 25.03%\n",
            "  lightly_drunk: 25.02%\n",
            "  sober: 24.98%\n",
            "  moderatly_drunk: 24.98%\n"
          ]
        }
      ],
      "source": [
        "def prepare_single_video(frames):\n",
        "    frames = frames[None, ...]\n",
        "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "    for i, batch in enumerate(frames):\n",
        "        video_length = batch.shape[0]\n",
        "        length = min(MAX_SEQ_LENGTH, video_length)\n",
        "        for j in range(length):\n",
        "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
        "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "    return frame_features, frame_mask\n",
        "\n",
        "\n",
        "def sequence_prediction(path):\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frames = load_video(os.path.join(\"test\", path))\n",
        "    frame_features, frame_mask = prepare_single_video(frames)\n",
        "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
        "\n",
        "    for i in np.argsort(probabilities)[::-1]:\n",
        "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
        "    return frames\n",
        "\n",
        "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
        "print(f\"Test video path: {test_video}\")\n",
        "\n",
        "test_frames = sequence_prediction(test_video)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d813641-337d-478d-a4d1-463eae152a44",
      "metadata": {
        "id": "4d813641-337d-478d-a4d1-463eae152a44"
      },
      "source": [
        "after getting the results of the video test we can open the video with the fucntion bellow to see what was the video and eventually see if the model predicted it well by replacing \"video_name.mp4\" in our code by the name of the video that we tested earlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6309d87b",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/content/drive/MyDrive/Colab%20Notebooks/dataset/test/dangerously_drunk%20(video1.mp4": {
              "data": "",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "6309d87b",
        "outputId": "4fd07a0c-c8a5-4528-a7ff-ad29fcd80c6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <video alt=\"test\" width=\"520\" height=\"440\" controls>\n",
              "        <source src=\"/content/drive/MyDrive/Colab Notebooks/dataset/test/dangerously_drunk (video1.mp4\" type=\"video/mp4\" style=\"height:300px;width:300px\">\n",
              "    </video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"\n",
        "    <video alt=\"test\" width=\"520\" height=\"440\" controls>\n",
        "        <source src=\"/content/drive/MyDrive/Colab Notebooks/dataset/test/dangerously_drunk (video1.mp4\" type=\"video/mp4\" style=\"height:300px;width:300px\">\n",
        "    </video>\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6150d7e2",
      "metadata": {
        "id": "6150d7e2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b16e337",
      "metadata": {
        "id": "0b16e337"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad15f322",
      "metadata": {
        "id": "ad15f322"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}